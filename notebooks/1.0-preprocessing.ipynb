{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Incidentes con armas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis descriptivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "gun_violence_df = pd.read_csv('../data/raw/gun-violence-data_01-2013_03-2018.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pequeña muestra de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forma de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables y sus tipos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resumen de información de las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descripción estadística de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, hacemos uso de la herramienta Pandas Profiling para dar un resumen de nuestro dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(gun_violence_df, title='Gun Violence Incidents', html={'style':{'full_width':True}})\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('../reports/descriptive_analysis', exist_ok=True)\n",
        "profile.to_file(output_file='../reports/descriptive_analysis/gun_violence_incidents_precleaning.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de los valores perdidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero, veremos en qué columnas existen valores nulos y cuántos de ellos hay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por tanto, las columnas con valores nulos son las siguientes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_columns = gun_violence_df.columns[gun_violence_df.isnull().any()]\n",
        "null_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y sus tipos de datos son:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df[null_columns].dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, generaremos la proporción de valores nulos en cada columna para una visión a más alto nivel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_proportions_df = pd.DataFrame(gun_violence_df[null_columns].isnull().sum() / gun_violence_df.shape[0], columns=['proportion']).sort_values(by='proportion', ascending=False)\n",
        "null_proportions_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una estrategia típica a seguir para la imputación de valores nulos es usar la media de la variable en caso de ser numérica, y la moda en caso de ser categórica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las variables `participant_relationship`, `location_description` y `participant_name` poseen más de un 50% de nulos. Por tanto, no tiene sentido la imputación de la moda (por ser categóricas), ya que esta no representa a la población, pues hay más valores nulos que completos. Por tanto, introduciremos un valor `Unknown`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Impute value 'Unknown' for null values in columns 'participant_relationship', 'location_description' and 'participant_name'\n",
        "gun_violence_df['participant_relationship'].fillna('Unknown', inplace=True)\n",
        "gun_violence_df['location_description'].fillna('Unknown', inplace=True)\n",
        "gun_violence_df['participant_name'].fillna('Unknown', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las variables `gun_stolen`, `gun_type` y `n_guns_involved` están directamente relacionadas. Según el número de armas involucradas, el tipo y si han sido robadas o no para cada una se indican en las otras dos columnas. Por ello, cuando el número de armas involucradas es nulo, las otras dos también. Por tanto, debemos seguir la misma estrategia para las tres columnas.\n",
        "\n",
        "Sin embargo, `n_guns_involved` es una variable numérica, mientras que `gun_stolen` y `gun_type` son categóricas. Por ello, tampoco tiene sentido utilizar o bien la media o bien la moda para todas.\n",
        "\n",
        "Finalmente, hemos valorado dos opciones:\n",
        "\n",
        "- Introducir un valor `Unknown`.\n",
        "- Utilizar una estrategia particular para el dominio.\n",
        "\n",
        "Hemos decidido crear una estrategia propia para nuestro problema.\n",
        "\n",
        "`gun_stolen` y `gun_type` están formateados de la siguiente manera:\n",
        "\n",
        "    \"0::<valor>||1::<valor>||...||<nº de armas involucradas - 1>::<valor>\"\n",
        "\n",
        "Además, en algunos registros existe una errata en la que se usa ':' en lugar de '::', o '|' en lugar de '||'.\n",
        "\n",
        "Por tanto, nuestra estrategia consiste en:\n",
        "\n",
        "1. Extraer estos valores correspondientes a cada arma involucrada del conjunto de datos.\n",
        "2. Reemplazar los valores nulos de `n_guns_involved` por su media redondeada a un entero.\n",
        "3. Reemplazar los valores nulos de `gun_stolen` y `gun_type` por una cadena en el formato establecido compuesta por _n_ armas, siendo _n_ la media redondeada que se ha imputado en los valores nulos de `n_guns_involved`, y cada una de ellas con el valor más frecuente para las armas involucradas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statistics import mode\n",
        "\n",
        "# Function to extract individual values from the given format\n",
        "def extract_values(column):\n",
        "    values = []\n",
        "    for row in column:\n",
        "        if pd.isnull(row):\n",
        "            continue\n",
        "        # Remove '||' and '|' separators\n",
        "        no_bars = list(filter(None, row.split('|')))\n",
        "        for item in no_bars:\n",
        "            if ':' in item:\n",
        "                # Remove '::' and ':' separators\n",
        "                no_separator = list(filter(None, item.split(':')))\n",
        "                values.append(no_separator[1])\n",
        "            # incident_characteristics column has a different format\n",
        "            else:\n",
        "                values.append(item)\n",
        "        \n",
        "    return values\n",
        "\n",
        "# Extract modes for gun_stolen and gun_type columns\n",
        "gun_stolen_mode = mode(extract_values(gun_violence_df['gun_stolen']))\n",
        "gun_type_mode = mode(extract_values(gun_violence_df['gun_type']))\n",
        "\n",
        "print(\"Moda de 'gun_stolen':\", gun_stolen_mode)\n",
        "print(\"Moda de 'gun_type':\", gun_type_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_guns_involved_mean = gun_violence_df['n_guns_involved'].mean()\n",
        "n_guns_involved_mean = round(n_guns_involved_mean, 0)\n",
        "print(\"Media redondeada de 'n_guns_involved':\", n_guns_involved_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, aplicaremos la estrategia mencionada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_values(values):\n",
        "    formatted_values = \"\"\n",
        "    n_values = len(values)\n",
        "    for i in range(n_values):\n",
        "        if i == n_values - 1:\n",
        "            formatted_values += str(i) + \"::\" + str(values[i])\n",
        "        else:\n",
        "            formatted_values += str(i) + \"::\" + str(values[i]) + \"||\"\n",
        "    return formatted_values\n",
        "\n",
        "# Impute values for null values in columns 'gun_stolen', 'gun_type' and 'n_guns_involved'\n",
        "gun_violence_df['n_guns_involved'].fillna(n_guns_involved_mean, inplace=True)\n",
        "gun_violence_df['gun_stolen'].fillna(format_values([gun_stolen_mode]), inplace=True)\n",
        "gun_violence_df['gun_type'].fillna(format_values([gun_type_mode]), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observando el resto de columnas con valores nulos, vemos que hay varias relacionadas con los participantes de los incidentes. Todas estas siguen el mismo formato que se expuso anteriormente. Por ello, hemos decidido volver a hacer uso de la extracción de valores de estas cadenas. Posteriormente, insertaremos la moda o la media redondeada (si son valores categóricos o numéricos, respectivamente) con el mismo formato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate mode for all the participant-related columns except 'participant_age'\n",
        "participant_age_group_mode = mode(extract_values(gun_violence_df['participant_age_group']))\n",
        "participant_gender_mode = mode(extract_values(gun_violence_df['participant_gender']))\n",
        "participant_type_mode = mode(extract_values(gun_violence_df['participant_type']))\n",
        "participant_status_mode = mode(extract_values(gun_violence_df['participant_status']))\n",
        "print(\"Moda de 'participant_age_group':\", participant_age_group_mode)\n",
        "print(\"Moda de 'participant_gender':\", participant_gender_mode)\n",
        "print(\"Moda de 'participant_type':\", participant_type_mode)\n",
        "print(\"Moda de 'participant_status':\", participant_status_mode)\n",
        "\n",
        "from statistics import mean\n",
        "# Calculate mean for 'participant_age'\n",
        "participant_ages = extract_values(gun_violence_df['participant_age'])\n",
        "participant_ages = [int(age) for age in participant_ages]\n",
        "participant_age_mean = mean(participant_ages)\n",
        "participant_age_mean = round(participant_age_mean, 0)\n",
        "print(\"Media redondeada de 'participant_age':\", participant_age_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Impute values for null values in participant-related columns\n",
        "gun_violence_df['participant_age_group'].fillna(format_values([participant_age_group_mode]), inplace=True)\n",
        "gun_violence_df['participant_gender'].fillna(format_values([participant_gender_mode]), inplace=True)\n",
        "gun_violence_df['participant_type'].fillna(format_values([participant_type_mode]), inplace=True)\n",
        "gun_violence_df['participant_status'].fillna(format_values([participant_status_mode]), inplace=True)\n",
        "gun_violence_df['participant_age'].fillna(format_values([int(participant_age_mean)]), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La columna `notes` consiste de anotaciones con información adicional del incidente en formato de texto. Por ello, la mayoría de sus valores son únicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show amount and proportion of unique values for 'notes' column\n",
        "notes_unique_values = gun_violence_df['notes'].unique()\n",
        "print(\"Cantidad de valores únicos en 'notes':\", len(notes_unique_values))\n",
        "print(\"Proporción de valores únicos en 'notes':\", len(notes_unique_values) / gun_violence_df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además, la información más relevante de estas notas (número de heridos, de muertos...) ya está incluida en otras variables del registro. Por ello, se ha decidido introducir un valor `No Notes` con el fin de no introducir ruido en la variable mediante otros métodos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df['notes'].fillna('No Notes', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las columnas `congressional_district`, `state_house_district`, `state_senate_district` son códigos de distrito dentro de cada estado. Por tanto, aunque dos registros tengan el mismo código de distrito para el congreso (por ejemplo), si están en distintos estados tienen significados totalmente distintos.\n",
        "\n",
        "Por esta razón, hemos decidido reemplazar los valores nulos de estas columnas por la moda de cada una de ellas dentro del estado correspondiente al registro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill null values in `congressional_district`, `state_house_district`, `state_senate_district` with the mode for the corresponding state\n",
        "states = gun_violence_df['state'].unique()\n",
        "state_congressional_district_mode = {}\n",
        "state_house_district_mode = {}\n",
        "state_senate_district_mode = {}\n",
        "for state in states:\n",
        "    state_congressional_district_mode[state] = mode(gun_violence_df[gun_violence_df['state'] == state]['congressional_district'])\n",
        "    state_house_district_mode[state] = mode(gun_violence_df[gun_violence_df['state'] == state]['state_house_district'])\n",
        "    state_senate_district_mode[state] = mode(gun_violence_df[gun_violence_df['state'] == state]['state_senate_district'])\n",
        "\n",
        "# Print modes for Alabama as an example\n",
        "print(\"Moda de 'congressional_district' para 'Alabama':\", state_congressional_district_mode['Alabama'])\n",
        "print(\"Moda de 'state_house_district' para 'Alabama':\", state_house_district_mode['Alabama'])\n",
        "print(\"Moda de 'state_senate_district' para 'Alabama':\", state_senate_district_mode['Alabama'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df['congressional_district'].fillna(gun_violence_df['state'].map(state_congressional_district_mode), inplace=True)\n",
        "gun_violence_df['state_house_district'].fillna(gun_violence_df['state'].map(state_house_district_mode), inplace=True)\n",
        "gun_violence_df['state_senate_district'].fillna(gun_violence_df['state'].map(state_senate_district_mode), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aun después de esto, hay algunos estados que cuyas columnas `state_house_district` y `state_senate_district` son todas nulas, por lo que siguen teniendo valores nulos.\n",
        "\n",
        "Para estas variables, introduciremos un valor `-1` que indicará que es desconocido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df['state_house_district'].fillna(-1, inplace=True)\n",
        "gun_violence_df['state_senate_district'].fillna(-1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las columnas `longitude` y `latitude` son las coordenadas del accidente. Para solventar los valores faltantes, utilizaremos la media para el estado que corresponda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill null values in `latitude` and `longitude` with the mean for the corresponding state\n",
        "state_latitude_mean = {}\n",
        "state_longitude_mean = {}\n",
        "for state in states:\n",
        "    state_latitude_mean[state] = gun_violence_df[gun_violence_df['state'] == state]['latitude'].mean()\n",
        "    state_longitude_mean[state] = gun_violence_df[gun_violence_df['state'] == state]['longitude'].mean()\n",
        "\n",
        "# Print means for Alabama as an example\n",
        "print(\"Media de 'latitude' para 'Alabama':\", state_latitude_mean['Alabama'])\n",
        "print(\"Media de 'longitude' para 'Alabama':\", state_longitude_mean['Alabama'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df['latitude'].fillna(gun_violence_df['state'].map(state_latitude_mean), inplace=True)\n",
        "gun_violence_df['longitude'].fillna(gun_violence_df['state'].map(state_longitude_mean), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La variable `address` es una variable referente a la ubicación demasiado concreta, por lo que la gran mayoría de sus valores son únicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "address_unique_values = gun_violence_df['address'].unique()\n",
        "print(\"Cantidad de valores únicos en 'address':\", len(address_unique_values))\n",
        "print(\"Proporción de valores únicos en 'address':\", len(address_unique_values) / gun_violence_df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por tanto, ya que ni la media ni la moda tienen sentido en este caso, hemos escogido utilizar un valor `Unknown` de nuevo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df['address'].fillna('Unknown', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "source_url_unique_values = gun_violence_df['source_url'].unique()\n",
        "print(\"Cantidad de valores únicos en 'source_url':\", len(source_url_unique_values))\n",
        "print(\"Proporción de valores únicos en 'source_url':\", len(source_url_unique_values) / gun_violence_df.shape[0])\n",
        "\n",
        "sources_unique_values = gun_violence_df['sources'].unique()\n",
        "print(\"Cantidad de valores únicos en 'sources':\", len(sources_unique_values))\n",
        "print(\"Proporción de valores únicos en 'sources':\", len(sources_unique_values) / gun_violence_df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por tanto, aplicaremos la misma técnica: la introducción de un valor `Unknown`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para las variables `url_source` y `sources` tenemos también una gran cantidad de valors únicos por su significado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df['source_url'].fillna('Unknown', inplace=True)\n",
        "gun_violence_df['sources'].fillna('Unknown', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por último, la variable `incident_characteristics` presenta el mismo formato previamente mencionado, común a muchas otras. Por ello, sustituiremos los valores nulos con la moda, respetando de nuevo el formato establecido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "incident_characteristics_mode = mode(extract_values(gun_violence_df['incident_characteristics']))\n",
        "print(\"Moda de 'incident_characteristics':\", incident_characteristics_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df['incident_characteristics'].fillna(format_values([incident_characteristics_mode]), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, conseguimos no tener valores nulos en el conjunto de datos al completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, trataremos los valores extremos o _outliers_ en las columnas no categóricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_columns = gun_violence_df.select_dtypes(include=['int64', 'float64']).columns\n",
        "numerical_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De las columnas de tipo numérico, `incident_id` es un identificador único. Las variables `congressional_district`, `state_house_district` y `state_senate_district`, a pesar de ser numéricas _a priori_, realmente representan una variable categórica. Por ello, no entrarán en el cálculo de valores extremos.\n",
        "\n",
        "Además, las variables `latitude` y `longitude` son datos espaciales que, al tratar el conjunto de datos la totalidad de los Estados Unidos, nos encontramos con un contexto geográfico muy amplio. Por ello, es natural encontrar latitudes y longitudes extremas (por ejemplo, las del estado de Alaska), y modificarlas podría distorsionar la realidad.\n",
        "\n",
        "Además, la variable `participant_age` es también una variable numérica, aunque se encuentra en el formato típico de estas variables en nuestro conjunto de datos. Por ello, extraeremos los valores individuales de cada participante.\n",
        "\n",
        "Por tanto, se tratarán los _outliers_ de las variables `n_killed`, `n_injured`, `n_guns_involved` y `participant_age`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract participant ages\n",
        "participant_ages = extract_values(gun_violence_df['participant_age'])\n",
        "participant_ages = [int(age) for age in participant_ages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero, visualizaremos los _outliers_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        " \n",
        "# Identify columns to plot\n",
        "numerical_columns = ['n_killed', 'n_injured', 'n_guns_involved']\n",
        "numerical_data = {\n",
        "    'n_killed': gun_violence_df['n_killed'],\n",
        "    'n_injured': gun_violence_df['n_injured'],\n",
        "    'n_guns_involved': gun_violence_df['n_guns_involved'],\n",
        "    'participant_age': participant_ages\n",
        "}\n",
        "\n",
        "# Plot boxplot for numerical_data\n",
        "fig, axes = plt.subplots(math.ceil(len(numerical_data) / 2), 2, figsize=(15, 15))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, (col, data) in zip(axes, numerical_data.items()):\n",
        "    sns.boxplot(data, ax=ax)\n",
        "    ax.set_title(col)\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los _boxplots_ nos muestran los datos que están fuera del 50% medio como puntos. Gracias a esta visualización, podemos ver que existen valores claramente erróneos, como edades de más de 100 años.\n",
        "\n",
        "Ahora, vamos a calcular los _outliers_ como los valores que se alejan 3 o más desviaciones estándar de la media (usando el método estadístico de _z-score_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "\n",
        "outliers = {\n",
        "    'n_killed': [],\n",
        "    'n_injured': [],\n",
        "    'n_guns_involved': [],\n",
        "    'participant_age': []\n",
        "}\n",
        "# Calculate outliers for numerical_data as values that are 3 standard deviations away from the mean\n",
        "for col, data in numerical_data.items():\n",
        "    data = np.array(data)\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    \n",
        "    threshold = 3\n",
        "    col_outliers = []\n",
        "    for x in data:\n",
        "        z_score = (x - mean) / std\n",
        "        if abs(z_score) > threshold:\n",
        "            col_outliers.append(x)\n",
        "    \n",
        "    outliers[col] = col_outliers\n",
        "    \n",
        "    print(\"Columna: \", col)\n",
        "    print(\"Media: \", mean)\n",
        "    print(\"Desviación estándar: \", std)\n",
        "    print(\"Número de outliers: \", len(col_outliers))\n",
        "    print(\"Proporción respecto al número de filas: \", len(col_outliers) / gun_violence_df.shape[0])\n",
        "    print(\"Outlier mínimo: \", min(col_outliers))\n",
        "    print(\"Outlier máximo: \", max(col_outliers), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove outliers from gun_violence_df\n",
        "for col in numerical_columns:\n",
        "    gun_violence_df = gun_violence_df[~gun_violence_df[col].isin(outliers[col])]\n",
        "\n",
        "outliers[\"participant_age\"] = [str(age) for age in outliers[\"participant_age\"]]\n",
        "substrings_to_remove = \"|\".join(outliers[\"participant_age\"])\n",
        "gun_violence_df = gun_violence_df[~gun_violence_df['participant_age'].str.contains(substrings_to_remove)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "participant_ages = extract_values(gun_violence_df['participant_age'])\n",
        "participant_ages = [int(age) for age in participant_ages]\n",
        "\n",
        "numerical_data = {\n",
        "    'n_killed': gun_violence_df['n_killed'],\n",
        "    'n_injured': gun_violence_df['n_injured'],\n",
        "    'n_guns_involved': gun_violence_df['n_guns_involved'],\n",
        "    'participant_age': participant_ages\n",
        "}\n",
        "\n",
        "# Plot boxplot for numerical_data without outliers\n",
        "fig, axes = plt.subplots(math.ceil(len(numerical_data) / 2), 2, figsize=(15, 15))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, (col, data) in zip(axes, numerical_data.items()):\n",
        "    data = np.array(data)\n",
        "    sns.boxplot(data, ax=ax)\n",
        "    ax.set_title(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos ver que en los nuevos _boxplots_ siguen existiendo _outliers_. Esto es porque utiliza el método del IQR, mientras que nosotros hemos utilizado el método del _z-score_, por lo que son distintos. Sin embargo, esto nos muestra que hemos reducido considerablemente el número de valores extremos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Profiling post-limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De nuevo, volvemos hacer uso del profiling para ver un resumen de nuestros datos tras la limpieza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(gun_violence_df, title='Gun Violence Incidents', html={'style':{'full_width':True}})\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('../reports/descriptive_analysis', exist_ok=True)\n",
        "profile.to_file(output_file='../reports/descriptive_analysis/gun_violence_incidents_postcleaning.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, procederemos a resolver los problemas de representación y codificación que se presenten en el conjunto de datos, de cara a seguir un formato común con las demás fuentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las variables que pueden presentarnos problemas de formato son:\n",
        "\n",
        "- La fecha, por ser esta una variable en la que puede haber diferencias de formato dependiendo de la fuente. Además, dependiendo de la hipótesis tendremos una granularidad de día o de año.\n",
        "- `gun_type`, `gun_stolen` y las variables referentes a los participantes (`participant_age`, `participant_gender`...), por tener un formato propio al conjunto de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para las segundas, hemos decidido representarlas como una lista, ya que Pandas lo permite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to extract individual values from the given format, and return them as a new column with lists\n",
        "def extract_values_to_lists(column):\n",
        "    new_column = {column.name: []}\n",
        "    for row in column:\n",
        "        new_row = []\n",
        "        if pd.isnull(row):\n",
        "            continue\n",
        "        # Remove '||' and '|' separators\n",
        "        no_bars = list(filter(None, row.split('|')))\n",
        "        for item in no_bars:\n",
        "            if ':' in item:\n",
        "                # Remove '::' and ':' separators\n",
        "                no_separator = list(filter(None, item.split(':')))\n",
        "                if len(no_separator) == 1:\n",
        "                    print(\"Empty value found in column\", column.name)\n",
        "                    new_row.append('Unknown')\n",
        "                    continue\n",
        "                # participant_age column has integer values\n",
        "                if column.name == 'participant_age':\n",
        "                    new_row.append(int(no_separator[1]))\n",
        "                else:\n",
        "                    new_row.append(no_separator[1])\n",
        "        new_column[column.name].append(new_row)\n",
        "        \n",
        "    return pd.DataFrame.from_dict(new_column)\n",
        "\n",
        "columns_to_format = ['gun_stolen', 'gun_type', 'participant_age', 'participant_age_group', 'participant_gender', 'participant_name', 'participant_relationship', 'participant_status', 'participant_type']\n",
        "\n",
        "for col in columns_to_format:\n",
        "    gun_violence_df[col] = extract_values_to_lists(gun_violence_df[col])[col].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df['date'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La fecha sigue el formato ISO 8601 extendido. Sin embargo, para nuestras hipótesis utilizaremos una granularidad de año. Por ello, separaremos la fecha en tres variables `year`, `month` y `day`, con el fin de poder unir nuestros datos después."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate date into year, month and day columns\n",
        "gun_violence_df['year'] = pd.DatetimeIndex(gun_violence_df['date']).year\n",
        "gun_violence_df['month'] = pd.DatetimeIndex(gun_violence_df['date']).month\n",
        "gun_violence_df['day'] = pd.DatetimeIndex(gun_violence_df['date']).day\n",
        "\n",
        "# Drop date column and reorder columns\n",
        "gun_violence_df.drop(columns=['date'], inplace=True)\n",
        "cols = gun_violence_df.columns.tolist()\n",
        "cols = [cols[0]] + cols[-3:] + cols[1:-3]\n",
        "gun_violence_df = gun_violence_df[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save gun_violence_df to csv\n",
        "import os\n",
        "os.makedirs('../data/interim', exist_ok=True)\n",
        "gun_violence_df.to_csv('../data/interim/gun_violence_incidents.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nuestras hipótesis sólo se refieren al número de incidentes, y la relación con las otras fuentes de datos será mediante la fecha y el estado. Por tanto, nos quedaremos con las siguientes columnas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_selected_columns = ['date', 'state']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya que los datos de 2018 sólo llegan hasta marzo, mientras que los de los demás años están completos, descartaremos también los datos de este año."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gun_violence_df = gun_violence_df[gun_violence_df['year'] != 2018]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además, dependiendo de la hipótesis para la que se usen estos datos reduciremos o no el número de registros. Para las dos primeras hipótesis, en las que usaremos solo este conjunto de datos, se quedará igual. Sin embargo, cuando se usen en conjunto con otros datos, descartaremos los datos previos al 2015, pues es el primer año para el que tenemos datos de pobreza (y poblaciones). A su vez, cuando se usen en conjunto con los datos de leyes, descartaremos los datos del estado \"District of Columbia\", pues no tenemos datos de leyes para este.\n",
        "\n",
        "Esto se hará justo antes de crear las tarjetas de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clima"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis descriptivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los datos de clima se proveen en un formato de texto difícil de tratar, por lo que primero deberemos analizar estos ficheros y convertirlos a un DataFrame. Esto comprende varias tareas de preprocesado más complejas que con los demás conjuntos de datos, por lo que se ha decidido realizar estas tareas en un _script_ aparte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../src/data')\n",
        "from parse_climate_data import parse_climate_data\n",
        "climate_data = ['../data/raw/temperature_data.txt', '../data/raw/precipitation_data.txt']\n",
        "climate_df = parse_climate_data('../data/raw/climate_state_codes.txt', climate_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pequeña muestra de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forma de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables y sus tipos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resumen de información de las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descripción estadística de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, hacemos uso de la herramienta Pandas Profiling para dar un resumen de nuestro dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(climate_df, title='Climate Data', html={'style':{'full_width':True}})\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('../reports/descriptive_analysis', exist_ok=True)\n",
        "profile.to_file(output_file='../reports/descriptive_analysis/climate_data_precleaning.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de los valores perdidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero, veremos en qué columnas existen valores nulos y cuántos de ellos hay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por tanto, las columnas con valores nulos son las siguientes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_columns = climate_df.columns[climate_df.isnull().any()]\n",
        "null_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al igual que en el anterior conjunto de datos, imputaremos la media para los valores nulos, por ser una variable numérica. Además, al ser datos climáticos que dependen del lugar (estado), utilizaremos la media del estado correspondiente al registro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing values with the mean value of the column for the corresponding state\n",
        "for col in null_columns:\n",
        "    climate_df[col] = climate_df.groupby('state')[col].transform(lambda x: x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, conseguimos no tener valores nulos en el conjunto de datos al completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Profiling post-limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De nuevo, volvemos hacer uso del profiling para ver un resumen de nuestros datos tras la limpieza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(climate_df, title='Climate Data', html={'style':{'full_width':True}})\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('../reports/descriptive_analysis', exist_ok=True)\n",
        "profile.to_file(output_file='../reports/descriptive_analysis/climate_data_postcleaning.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, trataremos los valores extremos o _outliers_ en las columnas no categóricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_columns = climate_df.select_dtypes(include=['int64', 'float64']).columns\n",
        "numerical_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya que `year` y `month` nos indican el tiempo en el que se realizó la medición, solo trataremos los _outliers_ para `average_temperature` y `average_precipitation`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero, visualizaremos los _outliers_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        " \n",
        "numerical_columns = numerical_columns.drop(['year', 'month'])\n",
        "\n",
        "fig, axes = plt.subplots(math.ceil(len(numerical_columns) / 2), 2, figsize=(15, 15))\n",
        "axes = axes.flatten()\n",
        "for ax, col in zip(axes, numerical_columns):\n",
        "    sns.boxplot(climate_df[col], ax=ax)\n",
        "    ax.set_title(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los _boxplots_ nos muestran los datos que están fuera del 50% medio como puntos. Gracias a esta visualización, podemos ver que existen outliers correspondientes a temperaturas bajo cero y precipitaciones muy altas.\n",
        "\n",
        "Ahora, vamos a calcular los _outliers_ como los valores que se alejan 3 o más desviaciones estándar de la media (usando el método estadístico de _z-score_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate outliers for numerical_columns as values that are 3 standard deviations away from the mean\n",
        "outliers = []\n",
        "for col in numerical_columns:\n",
        "    mean = climate_df[col].mean()\n",
        "    std = climate_df[col].std()\n",
        "    outliers = climate_df[(climate_df[col] < mean - 3*std) | (climate_df[col] > mean + 3*std)][col].values\n",
        "\n",
        "    print(\"Columna: \", col)\n",
        "    print(\"Media: \", mean)\n",
        "    print(\"Desviación estándar: \", std)\n",
        "    print(\"Número de outliers: \", len(outliers))\n",
        "    print(\"Proporción respecto al número de filas: \", len(outliers) / climate_df.shape[0])\n",
        "    if len(outliers) > 0:\n",
        "        print(\"Outlier mínimo: \", min(outliers))\n",
        "        print(\"Outlier máximo: \", max(outliers), \"\\n\")\n",
        "    else:\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya que estos valores pueden ser interesantes de analizar para ver qué ocurre en estados con temperaturas extremadamente bajas o precipitaciones extremadamente bajas, además de presentar tan pocos _outliers_, no eliminaremos ni sustituiremos estos valores. Además, cuando los pasemos a una unidad estándar serán menos aún."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los datos de temperatura de este conjunto se muestran en grados Fahrenheit. Nosotros estamos más acostumbrados a grados Celsius, por lo que los transformaremos a estos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df['average_temperature'] = (climate_df['average_temperature'] - 32) * 5/9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los datos de precipitaciones se presentan en centésimas de pulgada, que pasaremos a mm (unidad estándar)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "climate_df['average_precipitation'] = climate_df['average_precipitation'] * 0.254"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save climate_df to csv\n",
        "climate_df.to_csv('../data/interim/climate_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya que nuestros datos de incidentes van desde 2014 a 2017, descartaremos los datos de otros años."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove data previous to 2014 and after 2017 from climate_df\n",
        "climate_df = climate_df[climate_df['year'] > 2013]\n",
        "climate_df = climate_df[climate_df['year'] < 2018]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pobreza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis descriptivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "poverty_df = pd.read_csv('../data/raw/poverty_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pequeña muestra de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poverty_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forma de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poverty_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables y sus tipos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poverty_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resumen de información de las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poverty_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descripción estadística de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poverty_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, hacemos uso de la herramienta Pandas Profiling para dar un resumen de nuestro dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(poverty_df, title='Poverty Data', html={'style':{'full_width':True}})\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('../reports/descriptive_analysis', exist_ok=True)\n",
        "profile.to_file(output_file='../reports/descriptive_analysis/poverty_data_precleaning.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de los valores perdidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero, veremos en qué columnas existen valores nulos y cuántos de ellos hay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poverty_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por tanto, las columnas con valores nulos son las siguientes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_columns = poverty_df.columns[poverty_df.isnull().any()]\n",
        "null_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al igual que en el anterior conjunto de datos, imputaremos la media para los valores nulos, por ser una variable numérica. Además, al ser datos demográficos que dependen del estado, utilizaremos la media del estado correspondiente al registro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing values with the mean value of the column for the corresponding state\n",
        "for col in null_columns:\n",
        "    poverty_df[col] = poverty_df.groupby('state')[col].transform(lambda x: x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, conseguimos no tener valores nulos en el conjunto de datos al completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poverty_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, trataremos los valores extremos o _outliers_ en las columnas no categóricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_columns = poverty_df.select_dtypes(include=['int64', 'float64']).columns\n",
        "numerical_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descartaremos la variable `year` y trataremos los _outliers_ de las demás."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero, visualizaremos los _outliers_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        " \n",
        "numerical_columns = numerical_columns.drop('year')\n",
        "# Plot boxplots for numerical columns\n",
        "fig, ax = plt.subplots(math.ceil(len(numerical_columns)/3), 3, figsize=(15, 15))\n",
        "for i, col in enumerate(numerical_columns):\n",
        "    sns.boxplot(y=col, data=poverty_df, ax=ax[math.floor(i/3), i%3])\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los _boxplots_ nos muestran los datos que están fuera del 50% medio como puntos. Gracias a esta visualización, podemos ver que existen más outliers en las variables `population` y `in_poverty`. Esto es debido a que estas columnas son cantidades de habitantes, mientras que las otras son porcentajes. Esta diferencia de escalado hace que los valores extremos sean aún más extremos en estas.\n",
        "\n",
        "Ahora, vamos a calcular los _outliers_ como los valores que se alejan 3 o más desviaciones estándar de la media (usando el método estadístico de _z-score_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate outliers for numerical_data as values that are 3 standard deviations away from the mean\n",
        "outliers = {}\n",
        "for col in numerical_columns:\n",
        "    mean = poverty_df[col].mean()\n",
        "    std = poverty_df[col].std()\n",
        "    outliers[col] = poverty_df[(poverty_df[col] < mean - 3*std) | (poverty_df[col] > mean + 3*std)][col].values\n",
        "\n",
        "    print(\"Columna: \", col)\n",
        "    print(\"Media: \", mean)\n",
        "    print(\"Desviación estándar: \", std)\n",
        "    print(\"Número de outliers: \", len(outliers[col]))\n",
        "    print(\"Proporción respecto al número de filas: \", len(outliers[col]) / poverty_df.shape[0])\n",
        "    if len(outliers[col]) > 0:\n",
        "        print(\"Outlier mínimo: \", min(outliers[col]))\n",
        "        print(\"Outlier máximo: \", max(outliers[col]), \"\\n\")\n",
        "    else:\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya que los valores porcentuales no presentan _outliers_, y la renta (mediana) sólo presenta un _outlier_, no eliminaremos ningún _outlier_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Profiling post-limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De nuevo, volvemos hacer uso del profiling para ver un resumen de nuestros datos tras la limpieza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(poverty_df, title='Poverty Data', html={'style':{'full_width':True}})\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('../reports/descriptive_analysis', exist_ok=True)\n",
        "profile.to_file(output_file='../reports/descriptive_analysis/poverty_data_postcleaning.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los datos de este conjunto ya poseen un formato adecuado, por lo que no tenemos problemas de codificación/representación que resolver."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save poverty_df to csv\n",
        "os.makedirs('../data/interim', exist_ok=True)\n",
        "poverty_df.to_csv('../data/interim/poverty_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A primera vista, todas las variables parecen indicadores de pobreza importantes. Por ello, generaremos la matriz de correlación y veremos si es así."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute correlation matrix for poverty numerical data\n",
        "import numpy as np\n",
        "corr = poverty_df[numerical_columns].corr('pearson')\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Plot correlation matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(corr, annot=True, mask=mask, fmt='.2f', cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que existe una alta correlación entre algunos pares de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For each variable, show highly correlated variables (correlation > 0.5 or < -0.5)\n",
        "for col in numerical_columns:\n",
        "    print(col)\n",
        "    print(corr[((corr[col] > 0.5) | (corr[col] < -0.5)) & (corr[col] < 1)][col], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos observar que las variables están muy altamente correlacionadas. `population` e `in_poverty` están fuertemente correlacionadas, así como `poverty_rate` con `median_household_income`, `deep_poverty_rate`, `unemployment_rate` y `supplemental_poverty_measure`. Además, este `poverty_rate` tiene un coeficiente de Pearson muy cercano al umbral que hemos puesto (+-0,5) con `median_rent` y `withouth_health_insurance`.\n",
        "\n",
        "Por tanto, nos quedaremos solo con `poverty_rate` como indicador de pobreza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poverty_selected_columns = ['year', 'state', 'poverty_rate']\n",
        "poverty_selected_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Leyes sobre armas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis descriptivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "firearm_laws_database_df = pd.read_excel('../data/raw/firearm_laws_database.xlsx')\n",
        "firearm_laws_codebook_df = pd.read_excel('../data/raw/firearm_laws_codebook.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pequeña muestra de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_database_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_codebook_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forma de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_database_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_codebook_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables y sus tipos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_database_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_codebook_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resumen de información de las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_database_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_codebook_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como podemos ver, este dataset es algo peculiar. Cada registro se refiere a un estado, un año, y el resto de columnas a una ley en particular, que puede tomar como valor 0 (no activa) o 1 (activa). Además, el _codebook_ que usaremos para dividir las leyes en grupos tiene todas las variables en formato de texto, exceptuando el código de la categoría.\n",
        "\n",
        "Por estas características, creemos que no nos es útil realizar una descripción estadística de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de valores perdidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solo existen valores nulos en el _codebook_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_database_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_codebook_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por ser estos datos de tipo textual, los reemplazaremos con un valor `Unknown`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_columns = firearm_laws_codebook_df.columns[firearm_laws_codebook_df.isnull().any()]\n",
        "for col in null_columns:\n",
        "    firearm_laws_codebook_df[col].fillna('Unknown', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_codebook_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por las características peculiares del conjunto de datos comentadas anteriormente, creemos que no tiene sentido buscar _outliers_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además, los datos que necesitaremos están correctamente formateados. Sin embargo, los nombres de las columnas en el _codebook_ están escritos de manera distinta a los demás conjuntos de datos. Para homogeneizar las fuentes, las formatearemos correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_codebook_df.columns = firearm_laws_codebook_df.columns.str.lower().str.replace(' ', '_')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "También guardaremos los ficheros en formato csv en lugar de xlsx."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save firearm_laws_codebook_df to csv\n",
        "os.makedirs('../data/interim', exist_ok=True)\n",
        "firearm_laws_codebook_df.to_csv('../data/interim/firearm_laws_codebook.csv', index=False)\n",
        "\n",
        "# Save firearm_laws_database_df to csv\n",
        "os.makedirs('../data/interim', exist_ok=True)\n",
        "firearm_laws_database_df.to_csv('../data/interim/firearm_laws_database.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para el conjunto de datos en sí (_database_), utilizaremos todas las columnas, ya que agruparemos después por tipo de ley (categoría en el _codebook_) y nos serán necesarias. Sin embargo, nos desharemos de todos los datos previos a 2014, ya que no tenemos datos de incidentes antes de ese año.\n",
        "\n",
        "Para el _codebook_, por tanto, tomaremos sólo el código de la categoría y el nombre de la variable, para su uso después en la transformación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_codebook_selected_columns = ['category_code', 'variable_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firearm_laws_database_df = firearm_laws_database_df[firearm_laws_database_df['year'] >= 2013]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Poblaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis descriptivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "population_df = pd.read_csv('../data/raw/population_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pequeña muestra de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forma de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variables y sus tipos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resumen de información de las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descripción estadística de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de los valores perdidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero, veremos si existen nulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.isnull().values.any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como no los hay, no necesitamos realizar más operaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamiento de outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya que los valores del conjunto de datos son los habitantes de cada estado, habrá valores extremos correspondientes a los estados con más habitantes (e.g. California) o con menos (e.g. Alaska). Sin embargo, estos valores nos son necesarios, ya que los usaremos para escalar los datos de otros conjuntos para cada estado. Por tanto, no realizaremos ningún descarte de _outliers_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De nuevo, volvemos hacer uso del profiling para ver un resumen de nuestros datos tras la limpieza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este conjunto de datos presenta una variable por año para los distintos valores de población. Por ello, para coincidir con los demás datos, crearemos una variable `year` y modificaremos las demás columnas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = population_df.columns.tolist()\n",
        "\n",
        "# Create 'year' empty column right after 'NAME'\n",
        "cols.insert(5, 'year')\n",
        "\n",
        "# Keep the first 5 columns\n",
        "new_population_data = {col: [] for col in cols[:5]}\n",
        "new_population_data['year'] = []\n",
        "# Extract name without year from each of the other colums\n",
        "cols_to_be_grouped = cols[8:]\n",
        "for col in cols_to_be_grouped:\n",
        "    new_col = col[:-4]\n",
        "    new_col = new_col.replace('_', '')\n",
        "    new_population_data[new_col] = []\n",
        "\n",
        "# There are some columns with null values for 2010, which will be assigned None and handled later\n",
        "null_columns = ['RBIRTH', 'RDEATH', 'RNATURALINC', 'RINTERNATIONALMIG', 'RDOMESTICMIG', 'RNETMIG']\n",
        "\n",
        "# Repeat each row 10 times, one for each year\n",
        "for i in range(population_df.shape[0]):\n",
        "    # Add None values for null columns in 2010\n",
        "    for col in null_columns:\n",
        "        new_population_data[col].append(None)\n",
        "\n",
        "    for j in range(10):\n",
        "        new_population_data['year'].append(2010 + j)\n",
        "        # For each of the old columns which end with the year, add the value to the new column\n",
        "        for col in cols_to_be_grouped:\n",
        "            year = int(col[-4:])\n",
        "            if year == 2010 + j:\n",
        "                new_col = col[:-4]\n",
        "                new_col = new_col.replace('_', '')\n",
        "                new_population_data[new_col].append(population_df[col][i])\n",
        "        \n",
        "        # Add the values of the first 5 columns\n",
        "        for col in cols[:5]:\n",
        "            new_population_data[col].append(population_df[col][i])\n",
        "\n",
        "population_df = pd.DataFrame.from_dict(new_population_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Así, obtenemos el conjunto de datos con el nuevo formato de columnas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además, cambiaremos los nombres de las columnas a minúscula para seguir el mismo patrón en todos los conjuntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.columns = population_df.columns.str.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gracias a la nueva distribución, hemos observado que existen valores nulos para algunas variables en 2010. Los reemplazaremos por la media de la variable para ese estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Impute missing values with the mean value of the column for the corresponding state\n",
        "null_columns = population_df.columns[population_df.isnull().any()]\n",
        "for col in null_columns:\n",
        "    population_df[col] = population_df.groupby('name')[col].transform(lambda x: x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "population_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por tanto, nuestros datos limpios y con formato adecuado son los mismos que en crudo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('../data/interim', exist_ok=True)\n",
        "population_df.to_csv('../data/interim/population_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para el uso que le daremos a este conjunto de datos, nos interesan solo las poblaciones de los estados (en este conjunto se incluye también Puerto Rico) desde 2014 a 2017. Por tanto, seleccionaremos estos datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regions_to_remove = ['United States', 'Northeast Region', 'Midwest Region', 'South Region', 'West Region', 'Puerto Rico']\n",
        "selected_years = [2014, 2015, 2016, 2017]\n",
        "selected_population_columns = ['name', 'year', 'popestimate']\n",
        "\n",
        "population_df = population_df[~population_df['name'].isin(regions_to_remove)]\n",
        "population_df = population_df[population_df['year'].isin(selected_years)]\n",
        "population_df = population_df[selected_population_columns]\n",
        "population_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, crearemos una variable que nos indique si la fecha es fin de semana. Además, agregaremos el número de incidentes en cada estado y fecha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregation of number of incidents by state, year, month and day\n",
        "table_1 = gun_violence_df.groupby(['state', 'year', 'month', 'day']).size().reset_index(name='n_incidents')\n",
        "\n",
        "# Create column is_weekend\n",
        "import datetime\n",
        "table_1['is_weekend'] = table_1.apply(lambda row: 1 if datetime.datetime(row['year'], row['month'], row['day']).weekday() >= 5 else 0, axis=1)\n",
        "\n",
        "table_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, usaremos estas nuevas variables para agrupar los datos por año y estado, creando nuevas variables que nos indiquen cuántos incidentes diarios se han dado en un cierto año y estado en fines de semana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For each state and year, calculate the number of incidents in weekends\n",
        "table_1 = table_1.groupby(['state', 'year', 'is_weekend']).agg({'n_incidents': ['sum', 'count']}).reset_index()\n",
        "table_1.columns = ['state', 'year', 'is_weekend', 'n_incidents', 'n_days']\n",
        "\n",
        "# Divide sum by count to get the incidents per day\n",
        "table_1['n_incidents_per_day'] = table_1['n_incidents'] / table_1['n_days']\n",
        "table_1.drop(columns=['n_incidents', 'n_days'], inplace=True)\n",
        "\n",
        "table_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por último, escalaremos estos incidentes diarios por 100.000 habitantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get popestimate from population_df (which is the population) for each state and year and divide the number of incidents per day by 100000 to get the incidents per 100000 people\n",
        "\n",
        "table_1 = table_1.merge(population_df, left_on=['state', 'year'], right_on=['name', 'year'])\n",
        "table_1.drop(columns=['name'], inplace=True)\n",
        "table_1['n_incidents_per_day'] = table_1['n_incidents_per_day'] / table_1['popestimate'] * 100000\n",
        "table_1.drop(columns=['popestimate'], inplace=True)\n",
        "\n",
        "table_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Así, generamos la tarjeta de datos para las primera hipótesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save table_1 to csv\n",
        "os.makedirs('../data/processed', exist_ok=True)\n",
        "table_1.to_csv('../data/processed/incidents_weekend.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, generaremos la segunda tarjeta de datos. Agregaremos los incidentes ocurridos en cada estado, año y mes, junto con su temperatura media. Utilizaremos también la población del estado ese año para escalar el número de incidentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregation of number of incidents by state, year and month\n",
        "table_2 = gun_violence_df.groupby(['state', 'year', 'month']).size().reset_index(name='n_incidents')\n",
        "\n",
        "# Add average temperature for each state, year and month\n",
        "table_2 = table_2.merge(climate_df, on=['state', 'year', 'month'], how='left')\n",
        "\n",
        "# Scale the number of incidents by population (per 100,000 inhabitants) using population_df's popestimate column\n",
        "table_2 = table_2.merge(population_df, left_on=['state', 'year'], right_on=['name', 'year'])\n",
        "table_2.drop(columns=['name'], inplace=True)\n",
        "table_2['n_incidents'] = table_2['n_incidents'] / table_2['popestimate'] * 100000\n",
        "table_2.drop(columns=['popestimate'], inplace=True)\n",
        "\n",
        "# Drop 'District of Columbia' and 'Hawaii' because it has no data for average temperature\n",
        "table_2 = table_2[~table_2['state'].isin(['District of Columbia', 'Hawaii'])]\n",
        "\n",
        "table_2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save table_2 to csv\n",
        "table_2.to_csv('../data/processed/incidents_climate.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Después, generaremos la tercera tarjeta de datos. De igual manera, agregaremos los incidentes ocurridos en cada estado y año, junto con su ratio de pobreza. Utilizaremos también la población del estado ese año para escalar el número de incidentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregation of number of incidents by state and year\n",
        "table_3 = gun_violence_df.groupby(['state', 'year']).size().reset_index(name='n_incidents')\n",
        "\n",
        "table_3 = table_3[table_3['year'] > 2014]\n",
        "\n",
        "# Add poverty_rate column to table_3\n",
        "poverty_df = poverty_df[poverty_selected_columns]\n",
        "table_3 = pd.merge(table_3, poverty_df, on=['state', 'year'], how='left')\n",
        "\n",
        "# Scale the number of incidents by population (per 100,000 inhabitants) using population_df's popestimate column\n",
        "table_3 = table_3.merge(population_df, left_on=['state', 'year'], right_on=['name', 'year'])\n",
        "table_3.drop(columns=['name'], inplace=True)\n",
        "table_3['n_incidents'] = table_3['n_incidents'] / table_3['popestimate'] * 100000\n",
        "table_3.drop(columns=['popestimate'], inplace=True)\n",
        "\n",
        "table_3.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como no tenemos datos de pobreza para el año 2014, hemos eliminado los datos de incidentes de ese año en el tablón. Así, obtenemos el tablón para la tercera hipótesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save table_3 to csv\n",
        "os.makedirs('../data/processed', exist_ok=True)\n",
        "table_3.to_csv('../data/processed/incidents_population_poverty.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por último, generaremos la cuarta tarjeta de datos. Agregaremos de nuevo los incidentes por estado y año, y los escalaremos por población. Añadiremos el número de leyes activas, y crearemos una columna por cada categoría de ley."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregation of number of incidents by state and year\n",
        "table_4 = gun_violence_df.groupby(['state', 'year']).size().reset_index(name='n_incidents')\n",
        "\n",
        "# Add popestimate column from population_df to table_4 and scale the number of incidents by population (per 100,000 inhabitants)\n",
        "table_4 = table_4.merge(population_df, left_on=['state', 'year'], right_on=['name', 'year'])\n",
        "table_4.drop(columns=['name'], inplace=True)\n",
        "table_4['n_incidents'] = table_4['n_incidents'] / table_4['popestimate'] * 100000\n",
        "table_4.drop(columns=['popestimate'], inplace=True)\n",
        "\n",
        "# Add firearm laws columns to table_4\n",
        "table_4 = pd.merge(table_4, firearm_laws_database_df, on=['state', 'year'], how='left')\n",
        "table_4.head()\n",
        "\n",
        "# Create new columns for each category_code\n",
        "firearm_laws_codebook_df = firearm_laws_codebook_df[firearm_laws_codebook_selected_columns]\n",
        "category_columns = []\n",
        "for category_code in firearm_laws_codebook_df['category_code'].unique():\n",
        "    category_columns.append(\"laws_\" + str(category_code))\n",
        "\n",
        "for category_column in category_columns:\n",
        "    table_4[category_column] = 0\n",
        "\n",
        "# Fill category columns with the corresponding value. For a state and year, check all the variables and add 1 to the corresponding category column if the value is 1\n",
        "for index, row in table_4.iterrows():\n",
        "    for category_column in category_columns:\n",
        "        for variable_name in firearm_laws_codebook_df[firearm_laws_codebook_df['category_code'] == int(category_column[5:])]['variable_name']:\n",
        "            if row[variable_name] == 1:\n",
        "                table_4.at[index, category_column] += 1\n",
        "\n",
        "# Drop all the variables columns\n",
        "for variable_name in firearm_laws_codebook_df['variable_name']:\n",
        "    table_4.drop(columns=[variable_name], inplace=True)\n",
        "\n",
        "# Drop 'District of Columbia' data\n",
        "table_4 = table_4[table_4['state'] != 'District of Columbia']\n",
        "\n",
        "table_4.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Así, obtenemos la tarjeta de datos para la última hipótesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('../data/processed', exist_ok=True)\n",
        "table_4.to_csv('../data/processed/incidents_firearm_laws.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por último, se ha decidido generar una tarjeta de datos adicional que combine todos los datos (exceptuando los de si es fin de semana o no), para poder realizar un análisis más global. Por tanto, para resolver incompatibilidades entre distintos conjuntos de datos:\n",
        "\n",
        "- Se utilizará granularidad de año.\n",
        "- Se descartarán datos de Hawaii y District of Columbia.\n",
        "- Se tomarán sólo datos de 2015, 2016 y 2017."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## INCIDENTS\n",
        "# Aggregation of number of incidents by state and year\n",
        "table_5 = gun_violence_df.groupby(['state', 'year']).size().reset_index(name='n_incidents')\n",
        "\n",
        "# Add popestimate column from population_df to table_5 and scale the number of incidents by population (per 100,000 inhabitants)\n",
        "table_5 = table_5.merge(population_df, left_on=['state', 'year'], right_on=['name', 'year'])\n",
        "table_5.drop(columns=['name'], inplace=True)\n",
        "table_5['n_incidents'] = table_5['n_incidents'] / table_5['popestimate'] * 100000\n",
        "table_5.drop(columns=['popestimate'], inplace=True)\n",
        "\n",
        "## CLIMATE\n",
        "# Aggregation of average temperature and average precipitation by state and year (mean)\n",
        "climate_df = climate_df.groupby(['state', 'year']).mean().reset_index()\n",
        "climate_df.drop(columns=['month'], inplace=True)\n",
        "\n",
        "# Add average temperature column to table_5\n",
        "table_5 = pd.merge(table_5, climate_df, on=['state', 'year'], how='left')\n",
        "\n",
        "## POVERTY\n",
        "# Add poverty_rate column to table_5\n",
        "poverty_df = poverty_df[poverty_selected_columns]\n",
        "table_5 = pd.merge(table_5, poverty_df, on=['state', 'year'], how='left')\n",
        "\n",
        "## FIREARM LAWS\n",
        "# Add firearm laws columns to table_5\n",
        "table_5 = pd.merge(table_5, firearm_laws_database_df, on=['state', 'year'], how='left')\n",
        "table_5.head()\n",
        "\n",
        "# Create new columns for each category_code\n",
        "firearm_laws_codebook_df = firearm_laws_codebook_df[firearm_laws_codebook_selected_columns]\n",
        "category_columns = []\n",
        "for category_code in firearm_laws_codebook_df['category_code'].unique():\n",
        "    category_columns.append(\"laws_\" + str(category_code))\n",
        "\n",
        "for category_column in category_columns:\n",
        "    table_5[category_column] = 0\n",
        "\n",
        "# Fill category columns with the corresponding value. For a state and year, check all the variables and add 1 to the corresponding category column if the value is 1\n",
        "for index, row in table_5.iterrows():\n",
        "    for category_column in category_columns:\n",
        "        for variable_name in firearm_laws_codebook_df[firearm_laws_codebook_df['category_code'] == int(category_column[5:])]['variable_name']:\n",
        "            if row[variable_name] == 1:\n",
        "                table_5.at[index, category_column] += 1\n",
        "\n",
        "# Drop all the variables columns\n",
        "for variable_name in firearm_laws_codebook_df['variable_name']:\n",
        "    table_5.drop(columns=[variable_name], inplace=True)\n",
        "\n",
        "# Drop 'District of Columbia' and 'Hawaii' data\n",
        "table_5 = table_5[~table_5['state'].isin(['District of Columbia', 'Hawaii'])]\n",
        "\n",
        "# Drop data before 2015 and after 2017\n",
        "table_5 = table_5[table_5['year'] > 2014]\n",
        "table_5 = table_5[table_5['year'] < 2018]\n",
        "\n",
        "table_5.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save table_5 to csv\n",
        "os.makedirs('../data/processed', exist_ok=True)\n",
        "table_5.to_csv('../data/processed/incidents_combined.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
